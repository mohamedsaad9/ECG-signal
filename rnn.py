# -*- coding: utf-8 -*-
"""RNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f70OkkZa3veH4rhTbs1vQLhJjFlHFnE8
"""

import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.layers import Dense, SimpleRNN

# Loading data
ptbdb_abnormal = pd.read_csv("/content/ptbdb_abnormal.csv")
ptbdb_normal = pd.read_csv("/content/ptbdb_normal.csv")

# Renaming columns
ptbdb_abnormal.columns = list(range(len(ptbdb_abnormal.columns)))
ptbdb_normal.columns = list(range(len(ptbdb_normal.columns)))

# Renaming label column
ptbdb_abnormal = ptbdb_abnormal.rename({len(ptbdb_abnormal.columns)-1: 'Label'}, axis=1)
ptbdb_normal = ptbdb_normal.rename({len(ptbdb_normal.columns)-1: 'Label'}, axis=1)

# Taking only 4045 datapoints for abnormal class
ptbdb_abnormal = ptbdb_abnormal.head(4045)

# Concatenating abnormal and normal data, shuffling
data = pd.concat([ptbdb_abnormal, ptbdb_normal], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)

# Splitting into features and labels
y = data['Label'].copy()
X = data.drop('Label', axis=1).copy()

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)

# Model definition
inputs = tf.keras.Input(shape=(X_train.shape[1],))
expand = tf.expand_dims(inputs, axis=2)
gru = tf.keras.layers.SimpleRNN(256, return_sequences=True)(expand)
gru = tf.keras.layers.Dropout(0.2)(gru)
gru = tf.keras.layers.SimpleRNN(256, return_sequences=True)(gru)
flatten = tf.keras.layers.Flatten()(gru)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

# Compiling the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])
model.summary()

# Training the model
history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=50,
                    callbacks=[
                        tf.keras.callbacks.EarlyStopping(
                            monitor='val_loss',
                            patience=5,
                            restore_best_weights=True
                        )
                    ])

# Evaluate on validation set
val_loss, val_accuracy, val_auc = model.evaluate(X_train, y_train, verbose=0)
print("Validation Accuracy: {:.2f}%".format(val_accuracy * 100))

# Evaluate on test set
test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test, verbose=0)
print("Test Accuracy: {:.2f}%".format(test_accuracy * 100))

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, confusion_matrix, roc_auc_score, accuracy_score, precision_score, f1_score
# Evaluate on test set
test_results = model.evaluate(X_test, y_test, verbose=0)
print("Test Accuracy: {:.2f}%".format(test_results[1] * 100))

# Make predictions on the test set
y_pred_prob = model.predict(X_test).ravel()
y_pred = (y_pred_prob > 0.5).astype(int)

# Calculate confusion matrix and metrics
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)

# Calculate ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = roc_auc_score(y_test, y_pred_prob)

# Print metrics
print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")
print(f"Accuracy: {accuracy}")
print(f"Sensitivity: {sensitivity}")
print(f"Specificity: {specificity}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")
print(f"AUC: {roc_auc}")

# Plotting the ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()